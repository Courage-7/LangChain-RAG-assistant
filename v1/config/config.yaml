# RAG Document Assistant Configuration

# Embedding Configuration
embedding:
  model_name: "all-MiniLM-L6-v2"
  dimension: 384

# Vector Store Configuration
vector_store:
  path: "data/vector_store/faiss_index"  
  similarity_metric: "cosine"

# Document Chunking Configuration
chunking:
  chunk_size: 1000
  chunk_overlap: 200
  chunk_strategy: "recursive"

# Retrieval Configuration
retrieval:
  top_k: 5
  similarity_threshold: 0.7
  reranking_enabled: false

# LLM Configuration
llm:
  model_name: "gpt-3.5-turbo"
  temperature: 0.3
  max_tokens: 500
  system_prompt: "You are a helpful assistant that answers questions based on the provided documents."

# Evaluation Configuration
evaluation:
  metrics:
    - "precision"
    - "recall"
    - "f1_score"
    - "mrr"
    - "rouge"
    - "semantic_similarity"

huggingface:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
