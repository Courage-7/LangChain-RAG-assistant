{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Document Assistant Demo\n",
    "\n",
    "This notebook demonstrates the core functionality of the RAG Document Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the project directory to the path\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import custom modules\n",
    "from v1.src.config import Config\n",
    "from v1.src.embedding import DocumentEmbedder\n",
    "from v1.src.retriever import RAGRetriever\n",
    "from v1.src.query_optimization import QueryOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Components\n",
    "\n",
    "First, let's initialize the core components of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file found at v1/config/config.yaml\n",
      "Config loaded successfully\n",
      "Document embedder initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V\\Desktop\\rag_assistant\\v1\\src\\retriever.py:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embedding_model = HuggingFaceEmbeddings(\n",
      "c:\\Users\\V\\Desktop\\rag_assistant\\venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No vector store available. QA chain cannot be initialized.\n",
      "RAG retriever initialized\n",
      "Query optimizer initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V\\Desktop\\rag_assistant\\venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\V\\Desktop\\rag_assistant\\venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\V\\Desktop\\rag_assistant\\venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "config_path = \"v1/config/config.yaml\"\n",
    "\n",
    "# Check if config file exists\n",
    "if not os.path.exists(config_path):\n",
    "    print(f\"Config file not found at {config_path}\")\n",
    "else:\n",
    "    print(f\"Config file found at {config_path}\")\n",
    "\n",
    "# Initialize components with error handling\n",
    "try:\n",
    "    config = Config(config_path)\n",
    "    print(\"Config loaded successfully\")\n",
    "    \n",
    "    embedder = DocumentEmbedder(config_path)\n",
    "    print(\"Document embedder initialized\")\n",
    "    \n",
    "    retriever = RAGRetriever(config_path)\n",
    "    print(\"RAG retriever initialized\")\n",
    "    \n",
    "    optimizer = QueryOptimizer(config_path)\n",
    "    print(\"Query optimizer initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing components: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Processing\n",
    "\n",
    "Let's process a sample document and add it to our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import PyPDF2\n",
    "import docx\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def upload_file():\n",
    "    \"\"\"\n",
    "    Open a file dialog to upload a document\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the uploaded file\n",
    "    \"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    \n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select a Document\",\n",
    "        filetypes=[\n",
    "            (\"Supported Files\", \"*.pdf *.docx *.csv *.txt\"),\n",
    "            (\"PDF Files\", \"*.pdf\"),\n",
    "            (\"Word Documents\", \"*.docx\"),\n",
    "            (\"CSV Files\", \"*.csv\"),\n",
    "            (\"Text Files\", \"*.txt\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return file_path if file_path else None\n",
    "\n",
    "def preview_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Preview PDF file content\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file\n",
    "    \n",
    "    Returns:\n",
    "        str: Preview text of the PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            \n",
    "            # Limit preview to first 3 pages\n",
    "            preview_text = \"\"\n",
    "            for page_num in range(min(3, len(pdf_reader.pages))):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                preview_text += page.extract_text()\n",
    "            \n",
    "            return preview_text[:1000]  # Limit to 1000 characters\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def preview_docx(file_path):\n",
    "    \"\"\"\n",
    "    Preview DOCX file content\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Word document\n",
    "    \n",
    "    Returns:\n",
    "        str: Preview text of the document\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        \n",
    "        # Collect first few paragraphs\n",
    "        preview_text = \"\\n\".join([para.text for para in doc.paragraphs[:5]])\n",
    "        \n",
    "        return preview_text[:1000]  # Limit to 1000 characters\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing DOCX: {e}\")\n",
    "        return None\n",
    "\n",
    "def preview_csv(file_path):\n",
    "    \"\"\"\n",
    "    Preview CSV file content\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: First few rows of the CSV\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df.head()\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "def preview_txt(file_path):\n",
    "    \"\"\"\n",
    "    Preview TXT file content\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the text file\n",
    "    \n",
    "    Returns:\n",
    "        str: Preview text of the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            return text[:1000]  # Limit to 1000 characters\n",
    "    except Exception as e:\n",
    "        print(f\"Error previewing TXT: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_document(file_path=None, embedder=None):\n",
    "    \"\"\"\n",
    "    Process a document for embedding and vector store\n",
    "    \n",
    "    Args:\n",
    "        file_path (str, optional): Path to the document. \n",
    "                                   If None, opens file upload dialog\n",
    "        embedder (object, optional): Embedding and vector store handler\n",
    "    \n",
    "    Returns:\n",
    "        list: Document chunk IDs or None if processing fails\n",
    "    \"\"\"\n",
    "    # If no file path provided, open file upload dialog\n",
    "    if file_path is None:\n",
    "        file_path = upload_file()\n",
    "        \n",
    "        # Exit if no file selected\n",
    "        if file_path is None:\n",
    "            print(\"No file selected.\")\n",
    "            return None\n",
    "    \n",
    "    # Verify file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing document: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Determine file type for preview\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        # Preview document based on type\n",
    "        if file_extension == '.pdf':\n",
    "            preview = preview_pdf(file_path)\n",
    "            print(\"PDF Preview:\\n\", preview)\n",
    "        elif file_extension == '.docx':\n",
    "            preview = preview_docx(file_path)\n",
    "            print(\"DOCX Preview:\\n\", preview)\n",
    "        elif file_extension == '.csv':\n",
    "            preview = preview_csv(file_path)\n",
    "            print(\"CSV Preview:\\n\", preview)\n",
    "        elif file_extension == '.txt':\n",
    "            preview = preview_txt(file_path)\n",
    "            print(\"TXT Preview:\\n\", preview)\n",
    "        \n",
    "        # Only proceed with embedding if embedder is provided\n",
    "        if embedder is not None:\n",
    "            # Load and process document\n",
    "            documents = embedder.load_document(file_path)\n",
    "            print(f\"Loaded {len(documents)} document(s)\")\n",
    "            \n",
    "            # Add to vector store\n",
    "            doc_ids = embedder.add_documents(documents)\n",
    "            print(f\"Added {len(doc_ids)} document chunks to vector store\")\n",
    "            \n",
    "            return doc_ids\n",
    "        \n",
    "        return file_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (commented out)\n",
    "# def example_usage():\n",
    "#     # Scenario 1: Provide a file path\n",
    "#     # process_document('/path/to/your/document.pdf', embedder)\n",
    "#     \n",
    "#     # Scenario 2: Open file upload dialog\n",
    "#     # process_document(embedder=embedder)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a sample document (replace with your own document path)\n",
    "#sample_doc_path = \"path/to/your/sample/document.pdf\"  # Update this path\n",
    "\n",
    "# Uncomment to process the document\n",
    "# doc_ids = process_document(sample_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Optimization\n",
    "\n",
    "Let's test the query optimization functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query optimization\n",
    "def test_query_optimization(query):\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Optimize query\n",
    "        optimization_result = optimizer.optimize_query(query)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nOptimized query: {optimization_result['optimized_query']}\")\n",
    "        \n",
    "        print(\"\\nQuery variations:\")\n",
    "        for i, variation in enumerate(optimization_result['variations'], 1):\n",
    "            print(f\"  {i}. {variation}\")\n",
    "        \n",
    "        print(\"\\nExtracted keywords:\")\n",
    "        print(f\"  {', '.join(optimization_result['keywords'])}\")\n",
    "        \n",
    "        return optimization_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error optimizing query: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample query\n",
    "sample_query = \"What are the main benefits of RAG systems?\"\n",
    "optimization_result = test_query_optimization(sample_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Retrieval and Question Answering\n",
    "\n",
    "Now let's test the retrieval and question answering functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval and question answering\n",
    "def test_retrieval(query, use_optimization=True):\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Process query\n",
    "        if use_optimization:\n",
    "            print(\"Using query optimization...\")\n",
    "            optimization_result = optimizer.optimize_query(query)\n",
    "            optimized_query = optimization_result[\"optimized_query\"]\n",
    "            print(f\"Optimized query: {optimized_query}\")\n",
    "            result = retriever.answer_query(optimized_query)\n",
    "        else:\n",
    "            result = retriever.answer_query(query)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nAnswer:\")\n",
    "        print(result[\"answer\"])\n",
    "        \n",
    "        print(\"\\nRetrieved documents:\")\n",
    "        for i, doc in enumerate(result[\"documents\"], 1):\n",
    "            print(f\"\\nDocument {i}:\")\n",
    "            print(f\"Content: {doc.page_content[:200]}...\")\n",
    "            print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving answer: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample query\n",
    "sample_query = \"What are the main benefits of RAG systems?\"\n",
    "retrieval_result = test_retrieval(sample_query, use_optimization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Evaluation\n",
    "\n",
    "Let's evaluate the performance of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple performance evaluation\n",
    "import time\n",
    "\n",
    "def evaluate_performance(queries, use_optimization=True):\n",
    "    results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if use_optimization:\n",
    "            optimization_result = optimizer.optimize_query(query)\n",
    "            optimized_query = optimization_result[\"optimized_query\"]\n",
    "            result = retriever.answer_query(optimized_query)\n",
    "        else:\n",
    "            result = retriever.answer_query(query)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"time\": elapsed_time,\n",
    "            \"num_docs\": len(result[\"documents\"]) if \"documents\" in result else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample queries for evaluation\n",
    "sample_queries = [\n",
    "    \"What are the main benefits of RAG systems?\",\n",
    "    \"How does document chunking affect retrieval quality?\",\n",
    "    \"What embedding models work best for RAG?\",\n",
    "    \"Explain the difference between sparse and dense retrievers\"\n",
    "]\n",
    "\n",
    "# Evaluate with and without optimization\n",
    "print(\"Evaluating without optimization...\")\n",
    "results_without_opt = evaluate_performance(sample_queries, use_optimization=False)\n",
    "\n",
    "print(\"\\nEvaluating with optimization...\")\n",
    "results_with_opt = evaluate_performance(sample_queries, use_optimization=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults without optimization:\")\n",
    "display(results_without_opt)\n",
    "\n",
    "print(\"\\nResults with optimization:\")\n",
    "display(results_with_opt)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sample_queries)), results_without_opt['time'], width=0.4, label='Without Optimization')\n",
    "plt.bar([x + 0.4 for x in range(len(sample_queries))], results_with_opt['time'], width=0.4, label='With Optimization')\n",
    "plt.xlabel('Query')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Query Processing Time Comparison')\n",
    "plt.xticks([x + 0.2 for x in range(len(sample_queries))], [f'Query {i+1}' for i in range(len(sample_queries))])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook demonstrates the core functionality of our RAG Document Assistant. We've tested:\n",
    "\n",
    "1. Component initialization\n",
    "2. Document processing\n",
    "3. Query optimization\n",
    "4. Document retrieval and question answering\n",
    "5. Performance evaluation\n",
    "\n",
    "Next steps:\n",
    "- Fine-tune the embedding model\n",
    "- Optimize chunking parameters\n",
    "- Improve query optimization\n",
    "- Enhance the evaluation metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
